### S,A,R
#### States: Holding long, holding short, technical value (RSI, BB), return per minute
#### Actions: Buy, Sell, Cover, Short, do nothing
#### Rewards: Return from trade, return per 5 minutes

1.  Markov Decision Problems: states (s), actions (a), transition function T[s,a,s], Reward function R[s,a]. Reward-> $
2.  Find: optimal policy that will maximize reward.
3.  Algorithm-> Policy iteration and value iteration.
4.  most of the time T and R are unknown.
### Model based RL: Build a model T[s,a,s'] over time  and R[s,a]. We can apply value/policy iteration 
### Model Free or Q Learning


